{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MODELS\n",
    "- Go to import dataset; the steps below are preprocessing of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "from datetime import datetime\n",
    "\n",
    "from keras.layers import Embedding, LSTM, Dense, Conv1D, MaxPooling1D, Dropout, Activation\n",
    "from keras.models import Sequential\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_review = '/Users/Kenneth S. Hansen/Desktop/yelp/dataset/review.json'\n",
    "#y_business = '/Users/Kenneth S. Hansen/Desktop/yelp/dataset/business.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def yelp_data_generator(file_path):\n",
    "    with open(file_path, encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            # yield the the data line-by-line\n",
    "            yield json.loads(line.rstrip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create generator object\n",
    "reviews = yelp_data_generator(y_review)\n",
    "#business = yelp_data_generator(y_business)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:01:55.800990\n"
     ]
    }
   ],
   "source": [
    "# converting generator object to data frame\n",
    "t1 = datetime.now()\n",
    "df_reviews = pd.DataFrame.from_records(reviews, coerce_float=True, exclude=['review_id','user_id','date'])\n",
    "print(datetime.now() - t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t1 = datetime.now()\n",
    "df_business = pd.DataFrame.from_records(business, coerce_float=True, exclude=['name','neighborhood','address','city',\n",
    "                                                                             'latitude', 'longitude',\n",
    "                                                                             'stars', 'review_count', 'is_open',\n",
    "                                                                             'attributes', 'categories', 'hours'])\n",
    "print(datetime.now() - t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "response = requests.get('https://en.wikipedia.org/wiki/List_of_states_and_territories_of_the_United_States').text\n",
    "soup = BeautifulSoup(response, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "states = []\n",
    "\n",
    "table = soup.find('table', class_='wikitable')\n",
    "\n",
    "for row in table.find_all('tr')[2:]:\n",
    "    st = row.find_all('td')[0]\n",
    "    states.append(st.text)\n",
    "\n",
    "print(states)\n",
    "\n",
    "list_ = list(states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len(list_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_business_us = df_business.loc[ df_business.state.isin(list_), : ]\n",
    "df_business_us.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_final = pd.merge(df_business_us, df_reviews, on='business_id')\n",
    "df_final.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IMPORT dataset\n",
    "- The dataset is merged and filtered for non-us countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_final = pd.read_csv('/Users/Kenneth S. Hansen/Desktop/yelp/dataset_final/df_final.csv', encoding='ISO-8859-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_final.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downsampling - Binary Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Get a balanced sample of positive and negative reviews\n",
    "texts = [review for review in df_final['text']]\n",
    "\n",
    "# Based on the stars, I split the reviews into positive or negative\n",
    "#stars_y is from our review dataset, which I want to split on.\n",
    "\n",
    "binstars = [0 if review <= 3 else 1 for review in df_final['stars']]\n",
    "balanced_texts = []\n",
    "balanced_labels = []\n",
    "limit = 100000 # Change this to grow/shrink the dataset. In this case, I'm taking 100.000 positive and negative each.\n",
    "neg_pos_counts = [0, 0]\n",
    "for i in range(len(texts)):\n",
    "    polarity = binstars[i]\n",
    "    if neg_pos_counts[polarity] < limit:\n",
    "        balanced_texts.append(texts[i])\n",
    "        balanced_labels.append(binstars[i])\n",
    "        neg_pos_counts[polarity] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "print(Counter(balanced_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=20000)\n",
    "tokenizer.fit_on_texts(balanced_texts)\n",
    "sequences = tokenizer.texts_to_sequences(balanced_texts)\n",
    "data = pad_sequences(sequences, maxlen=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binary Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In line two, we add an Embedding layer. This layer lets the network expand each token to a larger vector, allowing the network to represent words in a meaningful way. We pass 20000 as the first argument, which is the size of our vocabulary (remember, we told the tokenizer to only use the 20 000 most common words earlier), and 128 as the second, which means that each token can be expanded to a vector of size 128. We give it an input_length of 300, which is the length of each of our sequences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#CNN\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.callbacks import ModelCheckpoint, CSVLogger, History\n",
    "\n",
    "#saving performance to log for visualization\n",
    "filepath=\"imp-{epoch:02d}-{val_acc:.2f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "csv_logger = CSVLogger('binary_cnn_training_history.csv')\n",
    "history = History()\n",
    "callbacks_list = [checkpoint, history, csv_logger]\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(20000, 300, input_length=300))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Conv1D(64, 5, activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=4))\n",
    "model.add(LSTM(300)) #128 before\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "binary_cnn = model.fit(data, np.array(balanced_labels), validation_split=0.3, epochs=10, callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization of the performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hist = pd.read_csv('/Users/Kenneth S. Hansen/desktop/yelp/Yelp_models/binary_cnn/binary_cnn_training_history.csv')\n",
    "hist = hist.drop('epoch', axis=1)\n",
    "plt.figure(figsize=(13,6))\n",
    "hist.plot(figsize=(13,6))\n",
    "plt.title('Neural Network for Sentiment Classification ')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save model for later use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "#save the tokenizer and model\n",
    "with open('keras_tokenizer.pickle', 'wb') as f:\n",
    "    pickle.dump(tokenizer, f) #tokenizer = the tokenized text above\n",
    "    \n",
    "binary_cnn.model.save('binary_yelp_sentiment_model') #name of the dave model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want to predict whether some new piece of text is positive or negative, we can load our model and get a prediction with:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### importing model and tokenized data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import pickle\n",
    " \n",
    "# load the tokenizer and the model\n",
    "with open(\"keras_tokenizer.pickle\", \"rb\") as f:\n",
    "   tk = pickle.load(f)\n",
    "\n",
    "model = load_model('binary_yelp_sentiment_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# replace with sentences that you want to classify\n",
    "newtexts = [\"I loved the food! It was awesome\", \"The service was of good quality\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# RECALL that we should NOT call \"fit\" on the tokenizer again\n",
    "sequences = tk.texts_to_sequences(newtexts)\n",
    "data = pad_sequences(sequences, maxlen=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get predictions for each of your new texts\n",
    "# Observe that the first sentence is negative and classified \n",
    "predictions = model.predict(data)\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recommender system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sentiment_predictor(input_, rating):\n",
    "    sequences = tk.texts_to_sequences(input_)\n",
    "  \n",
    "    padded_sequences = pad_sequences(sequences, maxlen = 300) #padding = 'post')\n",
    "\n",
    "    preds = model.predict(padded_sequences)\n",
    "\n",
    "    #average\n",
    "    predicted_rating = np.ndarray.round(preds[0])\n",
    "\n",
    "    print(input_)\n",
    "    print(rating)\n",
    "    print(predicted_rating)\n",
    "    if rating == 1 and preds < 0.5:\n",
    "        print('Are you sure about that score? It seems like you hated it')\n",
    "    elif rating == 0 and preds >= 0.5:\n",
    "        print(\"Hmm, it seems like you really like this place, are you sure about that rating?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_ = ['Probably the worst and most horrible place i have ever visited']\n",
    "rating = 1\n",
    "\n",
    "sentiment_predictor(input_, rating)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predidting the star rating - Multinominal classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing the dataset reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "import json\n",
    " \n",
    "# read the data from disk and split into lines\n",
    "# we use .strip() to remove the final (empty) line\n",
    "with open('/Users/Kenneth S. Hansen/Desktop/yelp/dataset/review.json', encoding='utf-8') as f:\n",
    "    reviews = f.read().strip().split(\"\\n\")\n",
    " \n",
    "# each line of the file is a separate JSON object\n",
    "reviews = [json.loads(review) for review in reviews] \n",
    " \n",
    "# we're interested in the text of each review \n",
    "# and the stars rating, so we load these into \n",
    "# separate lists\n",
    "texts = [review['text'] for review in reviews]\n",
    "stars = [review['stars'] for review in reviews]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "texts = df_reviews['text'].tolist()\n",
    "stars = df_reviews['stars'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4736897\n",
      "4736897\n"
     ]
    }
   ],
   "source": [
    "print(len(texts))\n",
    "print(len(stars))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Balancing the data into equal sizes of 1-5 rating reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    " \n",
    "def balance_classes(xs, ys):\n",
    "    freqs = Counter(ys)\n",
    "    max_allowable = 100000 #freqs.most_common()[-1][1] #Taking the lowest sample of the stars, and ensure downsampling\n",
    "    num_added = {clss: 0 for clss in freqs.keys()}\n",
    "    new_ys = []\n",
    "    new_xs = []\n",
    "    for i, y in enumerate(ys):\n",
    "        if num_added[y] < max_allowable:\n",
    "            new_ys.append(y)\n",
    "            new_xs.append(xs[i])\n",
    "            num_added[y] += 1\n",
    "    return new_xs, new_ys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({5: 1988003, 4: 1135830, 1: 639849, 3: 570819, 2: 402396})\n",
      "Counter({5: 100000, 3: 100000, 4: 100000, 1: 100000, 2: 100000})\n"
     ]
    }
   ],
   "source": [
    "#Confirm that the sampling occured succesfully - first line = the original allocaiton of star in the dataset\n",
    "#the second line shows the allocation of reviews when downsampled\n",
    "print(Counter(stars))\n",
    "balanced_x, balanced_y = balance_classes(texts, stars)\n",
    "print(Counter(balanced_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tokenizing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=20000) #currently only using the 20000 most common words #Increae? The average\n",
    "tokenizer.fit_on_texts(balanced_x)\n",
    "sequences = tokenizer.texts_to_sequences(balanced_x)\n",
    "data = pad_sequences(sequences, maxlen=300) #Average length 600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500000"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dummy encoding dependent variable - requried"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Dummy encode the target variable\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "# encode class values as integers\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(balanced_y)\n",
    "encoded_Y = encoder.transform(balanced_y)\n",
    "# convert integers to dummy variables (i.e. one hot encoded)\n",
    "dummy_y = to_categorical(encoded_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500000"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dummy_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Spliting into train and validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 70-30 split\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, dummy_y, test_size=0.3, random_state=9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiple classification - CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.callbacks import ModelCheckpoint, CSVLogger, History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#CNN using Keras' own embedding\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.callbacks import ModelCheckpoint, CSVLogger, History\n",
    "\n",
    "#saving performance to log for visualization\n",
    "filepath=\"imp-{epoch:02d}-{val_acc:.2f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "csv_logger = CSVLogger('multiple_class_keras_training_history.csv')\n",
    "history = History()\n",
    "callbacks_list = [checkpoint, history, csv_logger]\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(20000, 300, input_length=300))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Conv1D(64, 5, activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=4))\n",
    "model.add(LSTM(300)) #128 before\n",
    "model.add(Dense(5, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#The model ran for 17 hours\n",
    "multiple_keras = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "score, acc = model.evaluate(X_test, y_test)\n",
    "print('Score: %1.4f' % score)\n",
    "print('Accuracy: %1.4f' % acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Confusion matrix - with prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import pandas_ml as pdml\n",
    "from pandas_ml import ConfusionMatrix \n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import pandas_ml as pdml\n",
    "from pandas_ml import ConfusionMatrix \n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "y_true = y_test.argmax(axis=1)\n",
    "preds = model.predict_classes(X_test)\n",
    "\n",
    "cm = ConfusionMatrix(y_true, preds)\n",
    "cm.plot(backend='seaborn', normalized=True)\n",
    "plt.title('Confusion Matrix Stars prediction')\n",
    "plt.figure(figsize=(12, 10))\n",
    "plt.show()\n",
    "# cm.classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cm.classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(confusion_matrix(y_true, preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Saving the model for later use\n",
    "- Saving the model enables me to not train then entire model again (saving a LOT of time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Saving the CNN model\n",
    "# serialize model to JSON\n",
    "model_json = model.to_json()\n",
    "with open(\"/Users/Kenneth S. Hansen/desktop/Yelp_models/cnn_model2.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"/Users/Kenneth S. Hansen/desktop/Yelp_models/cnn_model2.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "C:\\Users\\Kenneth S. Hansen\\Desktop\\yelp\\Yelp_models\\cnn_multi_keras_emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import model_from_json\n",
    "# load json and create model\n",
    "json_file = open(\"/Users/Kenneth S. Hansen/Desktop/yelp/Yelp_models/cnn_multi_keras_emb/cnn_model2.json\", 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "\n",
    "# load weights into new model\n",
    "loaded_model.load_weights(\"/Users/Kenneth S. Hansen/Desktop/yelp/Yelp_models/cnn_multi_keras_emb/cnn_model2.h5\")\n",
    "print(\"Loaded model from disk\")\n",
    "from keras.models import model_from_json\n",
    "# load json and create model\n",
    "json_file = open(\"/Users/Kenneth S. Hansen/Desktop/yelp/Yelp_models/cnn_multi_keras_emb/cnn_model2.json\", 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "\n",
    "# load weights into new model\n",
    "loaded_model.load_weights(\"/Users/Kenneth S. Hansen/Desktop/yelp/Yelp_models/cnn_multi_keras_emb/cnn_model2.h5\")\n",
    "print(\"Loaded model from disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# evaluate the loaded model on test data\n",
    "loaded_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "score = loaded_model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"%s: %.2f%%\" % (loaded_model.metrics_names[1], score[1]*100)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization of the CNN model performance - based on the log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hist = pd.read_csv('/Users/Kenneth S. Hansen/desktop/Yelp_models/keras_training_history.csv')\n",
    "hist = hist.drop('epoch', axis=1)\n",
    "plt.figure(figsize=(13,6))\n",
    "hist.plot(figsize=(13,6))\n",
    "plt.title('Neural Network for Sentiment Classification ')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization in 2-dimensional space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import keras.backend as K\n",
    "\n",
    "def get_features_for_layer(X, trained_model, layer_number, batches=256):\n",
    "    \"\"\"\n",
    "    :param X: Batch with dimensions according to the models first layer input-shape\n",
    "    :param trained_model: Model to extract data from\n",
    "    :param layer_number: Index of the layer we want to extract features from.\n",
    "    :param batches: If set it will call the function in batches to save (gpu)memory\n",
    "    :return: \n",
    "    \"\"\"\n",
    "    get_features = K.function([trained_model.layers[0].input, K.learning_phase()],\n",
    "                              [trained_model.layers[layer_number].output])\n",
    "    \n",
    "    if batches:\n",
    "        g = array_batch_yield(X, batches)\n",
    "        features = []\n",
    "        for batch in g:\n",
    "            feature_batch = get_features([batch, 0])\n",
    "            features.append(feature_batch)\n",
    "            \n",
    "        features = np.concatenate(features, axis=1)[0]\n",
    "        \n",
    "    else:\n",
    "        features = get_features([X, 0])\n",
    "\n",
    "    return features\n",
    "\n",
    "def array_batch_yield(X, group_size):\n",
    "    for i in range(0, len(X), group_size):\n",
    "        yield X[i:i+group_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Extracting the recurrent LSTM layer below (layer 4)\n",
    "print(features_gru.shape) #Correspond to the training data (350.000 reviews), 128word vectors(dimensions)\n",
    "model.layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization of the worst performing model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Extracting LSTM layer with 128 word vectors (dimensions) for each review in X_train(350.000)\n",
    "features_gru = get_features_for_layer(X_train, model, 4, batches=500)\n",
    "\n",
    "tsne = TSNE()\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "\n",
    "f_gru_pca = pca.fit_transform(features_gru)\n",
    "\n",
    "\n",
    "p = Pipeline([\n",
    "        ('pca', pca), \n",
    "#         ('tsne', tsne)\n",
    "    ])\n",
    "feat = p.fit_transform(features_gru[:10000])\n",
    "\n",
    "df = pd.DataFrame(feat)\n",
    "df.columns = ['v1','v2']\n",
    "df['stars'] = y_train.argmax(axis=1)[:10000].astype(str)\n",
    "sns.lmplot('v1','v2', data=df, hue='stars', fit_reg=False,  scatter_kws={'alpha':0.5}, size=12)\n",
    "plt.title('PCA from LSTM layer')\n",
    "plt.xlabel('PCA1')\n",
    "plt.ylabel('PCA2')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization of the best performing model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Extracting LSTM layer with 128 word vectors (dimensions) for each review in X_train(350.000)\n",
    "features_gru = get_features_for_layer(X_train, model, 4, batches=500)\n",
    "\n",
    "tsne = TSNE()\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "\n",
    "f_gru_pca = pca.fit_transform(features_gru)\n",
    "\n",
    "\n",
    "p = Pipeline([\n",
    "        ('pca', pca), \n",
    "#         ('tsne', tsne)\n",
    "    ])\n",
    "feat = p.fit_transform(features_gru[:10000])\n",
    "\n",
    "df = pd.DataFrame(feat)\n",
    "df.columns = ['v1','v2']\n",
    "df['stars'] = y_train.argmax(axis=1)[:10000].astype(str)\n",
    "sns.lmplot('v1','v2', data=df, hue='stars', fit_reg=False,  scatter_kws={'alpha':0.5}, size=12)\n",
    "plt.title('PCA from LSTM layer')\n",
    "plt.xlabel('PCA1')\n",
    "plt.ylabel('PCA2')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features_gru = get_features_for_layer(X_train, model, 4, batches=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features_gru.shapec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fitting cnn with the built-in function - Validation is 50% of the data.\n",
    "- Here, we pass in our padded, tokenized texts as the first argument, and the labels as the second argument. We use validation_split=0.5 to tell our neural network that it should take half of the data to learn from, and that it should test itself on the other half. This means it will take half the reviews, along with their labels, and try to find patterns in the tokens that represent positive or negative labels. It will then try to predict the answers for the other half, without looking at the labels, and compare these predictions to the real labels, to see how good the patterns it learned are."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CNN WITHOUT spliting train and test. Instead validation on 50% Multiple classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Do NOT run this again - took approximately 6 hours\n",
    "multiple_cnn = model.fit(data, dummy_y, validation_split=0.5, epochs=10, callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The score may seem a bit low, but we need to keep in mind that with five rating classes, random guessing would be correctly only 20% of the time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Saving the cnn model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Saving the CNN model\n",
    "# serialize model to JSON\n",
    "model_json = model.to_json()\n",
    "with open(\"/Users/Kenneth S. Hansen/desktop/Yelp_models/cnn_model1.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"/Users/Kenneth S. Hansen/desktop/Yelp_models/cnn_model1.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading in the cnn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import model_from_json\n",
    "# load json and create model\n",
    "json_file = open(\"/Users/Kenneth S. Hansen/desktop/Yelp_models/cnn_model1.json\", 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "\n",
    "# load weights into new model\n",
    "loaded_model.load_weights(\"/Users/Kenneth S. Hansen/desktop/Yelp_models/cnn_model1.h5\")\n",
    "print(\"Loaded model from disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# evaluate loaded model on test data\n",
    "loaded_model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "\n",
    "score = loaded_model.evaluate(X, Y, verbose=0)\n",
    "print(\"%s: %.2f%%\" % (loaded_model.metrics_names[1], score[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OWN TRAINED WORD2VEC - CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binary Classification - own trained word2vec embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "BASE_DIR = ''\n",
    "W2V_DIR = '/Users/Kenneth S. Hansen/desktop/yelp/Yelp_models/word2vec300.txt'\n",
    "MAX_SEQUENCE_LENGTH = 300 #600 gives an error\n",
    "MAX_NB_WORDS = 20000\n",
    "EMBEDDING_DIM = 300\n",
    "VALIDATION_SPLIT = 0.2\n",
    "PRELOAD = True\n",
    "\n",
    "####\n",
    "def load_w2v_into_dict(w2v_path):\n",
    "    \"\"\"\n",
    "    :param w2v_path: strpath\n",
    "  \n",
    "    \"\"\"\n",
    "    embeddings_ix = {}\n",
    "    with open(w2v_path) as w2v_file:\n",
    "        for line in w2v_file:\n",
    "            val = line.split()\n",
    "            word = val[0]\n",
    "            vec = np.asarray(val[1:], dtype='float32')\n",
    "            embeddings_ix[word] = vec\n",
    "    return embeddings_ix\n",
    "\n",
    "###\n",
    "import operator\n",
    "WORD_INDEX_SORTED = sorted(tokenizer.word_index.items(), key=operator.itemgetter(1))\n",
    "\n",
    "###\n",
    "embedding_index = load_w2v_into_dict(W2V_DIR)\n",
    "nb_words = min(MAX_NB_WORDS, len(WORD_INDEX_SORTED))\n",
    "embedding_matrix = np.zeros((nb_words, EMBEDDING_DIM))\n",
    "for word, i in tokenizer.word_index.items():\n",
    "    if i >= MAX_NB_WORDS:\n",
    "        continue\n",
    "    embedding_vector = embedding_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        # words not found in embedding index will be all-zeros.\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "\n",
    "###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "#saving performance to log for visualization\n",
    "filepath=\"imp-{epoch:02d}-{val_acc:.2f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "csv_logger = CSVLogger('binary_own_embedding_training_history.csv')\n",
    "history = History()\n",
    "callbacks_list = [checkpoint, history, csv_logger]\n",
    "\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "#model.add(Embedding(20000, 128, input_length=300))\n",
    "model.add(Embedding(input_dim=nb_words, \n",
    "                    output_dim=EMBEDDING_DIM, \n",
    "                    input_length=MAX_SEQUENCE_LENGTH, \n",
    "                    weights=[embedding_matrix],\n",
    "                    trainable=False))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Conv1D(64, 5, activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=4))\n",
    "model.add(LSTM(128))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fitting the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "binary_cnn_own_emb = model.fit(data, np.array(balanced_labels), validation_split=0.3, epochs=10, callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "#save the tokenizer and model\n",
    "with open('keras_tokenizer.pickle', 'wb') as f:\n",
    "    pickle.dump(tokenizer, f) #tokenizer = the tokenized text above\n",
    "    \n",
    "binary_cnn_own_emb.model.save('binary_cnn_own_yelp_sentiment_model') #name of the dave model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualization of the performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hist = pd.read_csv('/Users/Kenneth S. Hansen/desktop/binary_own_embedding_training_history.csv')\n",
    "hist = hist.drop('epoch', axis=1)\n",
    "plt.figure(figsize=(13,6))\n",
    "hist.plot(figsize=(13,6))\n",
    "plt.title('Neural Network for Sentiment Classification ')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multinominal classification - own trained word2vec embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20000"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(embedding_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "BASE_DIR = ''\n",
    "W2V_DIR = '/Users/Kenneth S. Hansen/desktop/yelp/Yelp_models/word2vec300.txt'\n",
    "MAX_SEQUENCE_LENGTH = 300\n",
    "MAX_NB_WORDS = 20000\n",
    "EMBEDDING_DIM = 300\n",
    "VALIDATION_SPLIT = 0.2\n",
    "PRELOAD = True\n",
    "\n",
    "####\n",
    "def load_w2v_into_dict(w2v_path):\n",
    "    \"\"\"\n",
    "    :param w2v_path: strpath\n",
    "  \n",
    "    \"\"\"\n",
    "    embeddings_ix = {}\n",
    "    with open(w2v_path) as w2v_file:\n",
    "        for line in w2v_file:\n",
    "            val = line.split()\n",
    "            word = val[0]\n",
    "            vec = np.asarray(val[1:], dtype='float32')\n",
    "            embeddings_ix[word] = vec\n",
    "    return embeddings_ix\n",
    "\n",
    "###\n",
    "import operator\n",
    "WORD_INDEX_SORTED = sorted(tokenizer.word_index.items(), key=operator.itemgetter(1))\n",
    "\n",
    "###\n",
    "embedding_index = load_w2v_into_dict(W2V_DIR)\n",
    "nb_words = min(MAX_NB_WORDS, len(WORD_INDEX_SORTED))\n",
    "embedding_matrix = np.zeros((nb_words, EMBEDDING_DIM))\n",
    "for word, i in tokenizer.word_index.items():\n",
    "    if i >= MAX_NB_WORDS:\n",
    "        continue\n",
    "    embedding_vector = embedding_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        # words not found in embedding index will be all-zeros.\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "\n",
    "###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "#saving performance to log for visualization\n",
    "filepath=\"imp-{epoch:02d}-{val_acc:.2f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "csv_logger = CSVLogger('multipleclass_own_embedding_training_history.csv')\n",
    "history = History()\n",
    "callbacks_list = [checkpoint, history, csv_logger]\n",
    "\n",
    "model = Sequential()\n",
    "#model.add(Embedding(20000, 128, input_length=300))\n",
    "model.add(Embedding(input_dim=nb_words, \n",
    "                    output_dim=EMBEDDING_DIM, \n",
    "                    input_length=MAX_SEQUENCE_LENGTH, \n",
    "                    weights=[embedding_matrix], \n",
    "                    trainable=False))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Conv1D(64, 5, activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=4))\n",
    "model.add(LSTM(128))\n",
    "model.add(Dense(5, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Fitting the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 350000 samples, validate on 150000 samples\n",
      "Epoch 1/10\n",
      "349984/350000 [============================>.] - ETA: 0s - loss: 0.9485 - acc: 0.5836Epoch 00000: val_acc improved from -inf to 0.60753, saving model to imp-00-0.61.hdf5\n",
      "350000/350000 [==============================] - 3678s - loss: 0.9485 - acc: 0.5836 - val_loss: 0.8935 - val_acc: 0.6075\n",
      "Epoch 2/10\n",
      "349984/350000 [============================>.] - ETA: 0s - loss: 0.8990 - acc: 0.6052Epoch 00001: val_acc improved from 0.60753 to 0.61149, saving model to imp-01-0.61.hdf5\n",
      "350000/350000 [==============================] - 3597s - loss: 0.8990 - acc: 0.6052 - val_loss: 0.8890 - val_acc: 0.6115\n",
      "Epoch 3/10\n",
      "349984/350000 [============================>.] - ETA: 0s - loss: 0.8856 - acc: 0.6118Epoch 00002: val_acc improved from 0.61149 to 0.61621, saving model to imp-02-0.62.hdf5\n",
      "350000/350000 [==============================] - 3555s - loss: 0.8856 - acc: 0.6118 - val_loss: 0.8781 - val_acc: 0.6162\n",
      "Epoch 4/10\n",
      "349984/350000 [============================>.] - ETA: 0s - loss: 0.8795 - acc: 0.6144Epoch 00003: val_acc improved from 0.61621 to 0.61804, saving model to imp-03-0.62.hdf5\n",
      "350000/350000 [==============================] - 3548s - loss: 0.8795 - acc: 0.6144 - val_loss: 0.8742 - val_acc: 0.6180\n",
      "Epoch 5/10\n",
      "349984/350000 [============================>.] - ETA: 0s - loss: 0.8751 - acc: 0.6172Epoch 00004: val_acc did not improve\n",
      "350000/350000 [==============================] - 3547s - loss: 0.8751 - acc: 0.6172 - val_loss: 0.8783 - val_acc: 0.6157\n",
      "Epoch 6/10\n",
      "349984/350000 [============================>.] - ETA: 0s - loss: 0.8715 - acc: 0.6185Epoch 00005: val_acc improved from 0.61804 to 0.61965, saving model to imp-05-0.62.hdf5\n",
      "350000/350000 [==============================] - 3546s - loss: 0.8715 - acc: 0.6185 - val_loss: 0.8717 - val_acc: 0.6197\n",
      "Epoch 7/10\n",
      "349984/350000 [============================>.] - ETA: 0s - loss: 0.8697 - acc: 0.6195Epoch 00006: val_acc improved from 0.61965 to 0.61999, saving model to imp-06-0.62.hdf5\n",
      "350000/350000 [==============================] - 3549s - loss: 0.8697 - acc: 0.6195 - val_loss: 0.8714 - val_acc: 0.6200\n",
      "Epoch 8/10\n",
      "349984/350000 [============================>.] - ETA: 0s - loss: 0.8674 - acc: 0.6203Epoch 00007: val_acc did not improve\n",
      "350000/350000 [==============================] - 3542s - loss: 0.8674 - acc: 0.6203 - val_loss: 0.8790 - val_acc: 0.6141\n",
      "Epoch 9/10\n",
      "349984/350000 [============================>.] - ETA: 0s - loss: 0.8646 - acc: 0.6210Epoch 00008: val_acc did not improve\n",
      "350000/350000 [==============================] - 3543s - loss: 0.8645 - acc: 0.6210 - val_loss: 0.8720 - val_acc: 0.6199\n",
      "Epoch 10/10\n",
      "349984/350000 [============================>.] - ETA: 0s - loss: 0.8649 - acc: 0.6219Epoch 00009: val_acc did not improve\n",
      "350000/350000 [==============================] - 3539s - loss: 0.8649 - acc: 0.6219 - val_loss: 0.8729 - val_acc: 0.6172\n"
     ]
    }
   ],
   "source": [
    "multiple_own_emb = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150000/150000 [==============================] - 989s   \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[  5.74972391e-01,   2.65437663e-01,   1.04902931e-01,\n",
       "          3.65879312e-02,   1.80990938e-02],\n",
       "       [  1.40917793e-01,   5.01271427e-01,   2.85158098e-01,\n",
       "          5.51784560e-02,   1.74742006e-02],\n",
       "       [  7.80646563e-01,   1.43324405e-01,   4.14699875e-02,\n",
       "          1.41938571e-02,   2.03651395e-02],\n",
       "       ..., \n",
       "       [  1.26599204e-02,   5.38751595e-02,   3.60400558e-01,\n",
       "          4.73985344e-01,   9.90790352e-02],\n",
       "       [  1.48387032e-03,   7.43175372e-02,   7.56560624e-01,\n",
       "          1.61826581e-01,   5.81146544e-03],\n",
       "       [  7.92205334e-03,   3.05139095e-01,   6.56624794e-01,\n",
       "          2.96547748e-02,   6.59266021e-04]], dtype=float32)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multiple_own_emb.model.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Visualization of the performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x16583695d68>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAwQAAAF1CAYAAABWGi2vAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nEREREZEh9v83+j1hrJHNLwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x166241931d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "hist = pd.read_csv('/Users/Kenneth S. Hansen/desktop/multipleclass_own_embedding_training_history.csv')\n",
    "hist = hist.drop('epoch', axis=1)\n",
    "plt.figure(figsize=(13,6))\n",
    "hist.plot(figsize=(13,6))\n",
    "plt.title('Neural Network for Sentiment Classification ')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Confusion matrix\n",
    "- Requires test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXIAAAEWCAYAAAB7QRxFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAHfhJREFUeJzt3XmcXFWd9/HPNw1J2EEjKkkkoAEEGcMiOvKoiIBxI7wG\ncQIqxFEzzMAIKiqOvBBRB3REnXmMM0TFBZTgMmLUPEYGCcpqAgQwYQsBTALKTtiT7v49f9zTcFPp\nWrq7qqtO5fvO675Sdz2/W1X9q1PnnntKEYGZmeVrTLsDMDOzkXEiNzPLnBO5mVnmnMjNzDLnRG5m\nljkncjOzzDmRt5mkLST9UtJjkn4yguO8V9JvmxlbO0j6f5KOa3ccnUzSFEkhabM0P6znTNLLJD0h\nqaf5UdpociJvkKRjJC1Jb/z70h/P/2nCod8NvBh4YUQcNdyDRMQPI+KwJsSzAUkHpaTx84rlr07L\nFzV4nDMkXVBvu4h4W0R8fxhxjpV0jqTV6TW6W9LXS+vvlnTIUI+bg0afs8rnICL+HBFbR0RfayO0\nVnMib4CkjwFfB/6NIum+DPgmMKMJh98ZuD0ieptwrFZ5APhbSS8sLTsOuL1ZBagwkvfjp4H9gQOA\nbYCDgOubEBoAraq1NuG8zSAiPNWYgO2AJ4CjamwzjiLR35umrwPj0rqDgNXAx4H7gfuAD6R1nwPW\nAetTGR8EzgAuKB17ChDAZml+FrASeBy4C3hvafkVpf1eDywGHkv/v760bhHweeDKdJzfAhOqnNtA\n/P8NnJCW9QBrgNOBRaVt/wNYBawFrgPekJZPrzjPG0txfDHF8TTwirTsQ2n9fwE/Kx3/S8ClgAaJ\n81fAyVXO4XygP5XxBPDJtPwnwF/Sc/R7YK/SPt9L5S8AngQOAd4OLE/P2RrglCrlzUrn9I107FuB\nt1Q8/5XnvR3wnfT+WAN8AegpPd9fAR5Mr/0JFe+J556zNP9h4JYU53Jg38GeAzZ+b+0EzAceBlYA\nHy4d8wzgx8AP0nGXAfu3++/TU3p92h1Ap08pCfUOvNmrbHMmcA2wI/Ai4Crg82ndQWn/M4HNUzJ4\nCtghrT+DDRN35fxzf2zAVhRJcve07qUDyYdSIgdeADwCvD/td3Saf2Favwi4E9gN2CLNn13l3A6i\nSOSvB65Ny94OLAQ+xIaJ/H3AC1OZH6dIkuMHO69SHH8G9kr7bM6GiXxLilr/LOANFIlsUpU4T0vH\n+mdgbyqSPXA3cEjFsn+gqL0PfBAvLa37HkUSPpDim+t4iiQ78OG0A7BvlVhmpdf8o+mc/j4d6wU1\nzvvnwLnpNd4R+CPwj2n74yk+DCan1/YyqiRy4CiKD4LXAKL4kNh5sOeAjRP57ym+aY4HplF8Ezu4\n9Po9k177HuAs4Jp2/316KiZ/pavvhcCDUbvp473AmRFxf0Q8QFHTfn9p/fq0fn1ELKCoEe0+zHj6\ngVdJ2iIi7ouIZYNs8w7gjog4PyJ6I+JCikTwrtI2342I2yPiaYqa1rRahUbEVcALJO0OHEtRM6vc\n5oKIeCiVeQ5Fgqx3nt+LiGVpn/UVx3uK4nn8KnAB8C8RsbrKcc6iqLG/F1gCrKl3ATAizouIxyPi\nWYpE9WpJ25U2+UVEXBkR/RHxDMXruKekbSPikYio1XRzP/D19JpfBNxG8bpsdN4UyfntFN8onoyI\n+4GvATPTtu9Jx1oVEQ+nc63mQ8CXI2JxFFZExD21ngcASZMpPrQ+FRHPRMRS4NsUr/WAKyJiQRRt\n6ucDr653XBsdTuT1PQRMGOghUMVOQPmP5Z607LljVHwQPAVsPdRAIuJJitrd8cB9kn4taY8G4hmI\naWJp/i/DiOd84ETgzRQ1yA1IOkXSLakHzqMUzQUT6hxzVa2VEXEtRXOCKD5wqm3XFxFzIuJAYHuK\npovzJL1ysO0l9Ug6W9KdktZS1FapiLcytiMpEu49ki6X9Lc1Ql8TEeUR6SrfE+Vj70xRK79P0qPp\nuTuXomZO2q+8fa3EPJni29ZQ7QQ8HBGPV5RT6z0zvs7fhY0SJ/L6rgaeBY6osc29FH+MA16Wlg3H\nkxRNCgNeUl4ZEQsj4lCKZpVbgW81EM9ATGuGGdOA8ymaLhak2vJzJL2Bot31PRTNRttTNCdoIPQq\nx6w5/KakEyhq9vem49cVEU9HxByK5qQ9q5RzDMXF6kMoPnCmDBRZLbZUy51BkWAvpsYHCzBRUvlY\nle+J8rFXUbzHJkTE9mnaNiL2Suvvo0jQ5WNVswp4eZV1tZ7reym+cW1TUc5I3zM2CpzI64iIxygu\n6s2RdISkLSVtLultkr6cNrsQOE3SiyRNSNvX7WpXxVLgjamP73YUvTEAkPRiSTMkbUXxh/8ERVNL\npQXAbqnL5GaS/p4iof1qmDEBEBF3AW8CPjPI6m0o2oUfADaTdDqwbWn9X4EpQ+mhIWk3iot+76No\nYvmkpEGbgCSdnLpKbpHO+bgU0w2l8netiPdZim9cW1L0SKoVy9jUV3+71AS0lsGf+wE7Ah9J75Wj\ngFdSvC4biYj7KC44nyNpW0ljJL1c0pvSJj9Ox5okaQfg1Brlfhs4RdJ+qUfMKyQNfKhXPgflGFZR\nXNs5S9J4SX9DcfF9uO9jG0VO5A1I7b0fo7ig9gBFredEiloZFMlmCXATcDNFt7cvDLOsS4CL0rGu\nY8PkOybFcS9Fz4I3Af80yDEeAt5JccHxIYqa7Dsj4sHhxFRx7CsiYrBvGwuB31BcnLyH4sJYuTlg\n4GanhyTV7RaYvrJfAHwpIm6MiDuAfwXOlzRukF2eAs6h+Pr/IEXPjiMjYmVafxbFh+2jkk6haOO/\nh6LGuZziYnU97wfuTk0xx1O0x1dzLTA1xfJF4N3pdanmWGBsiuUR4KcU37qg+Na1ELiR4r31P9UO\nEhE/SeX9iKJ3ycUUbfCw8XNQ6WiKbyb3UjSdfTYi/rdGzNYhtGEznpmNlKRZFL1ImnHDmFldrpGb\nmWXOidzMLHNuWjEzy5xr5GZmmevYzvzrH1zZdV8V3vLqD7c7hJb409o/tzuEplv77FP1N8qQ6m+S\npfXr1oz41IaSczafsGtHPZWukZuZZa5ja+RmZqOqP99h2Z3IzcwA+jr5JwFqcyI3MwMiao240Nmc\nyM3MAPqdyM3M8uYauZlZ5nyx08wsc66Rm5nlLdxrxcwsc77YaWaWOTetmJllLuOLnR5rxcwMihp5\no1MdkqZLuk3SCkkb/caqpK9JWpqm2yU9WlrXV1o3v5HQXSM3M4Om3aIvqQeYAxwKrAYWS5ofEcsH\ntomIj5a2/xdgn9Ihno6IQX9kvBrXyM3MoLjY2ehU2wHAiohYGRHrgHnAjBrbHw1cOJLQncjNzICI\nvoanOiYCq0rzq9OyjUjaGdgF+F1p8XhJSyRdI+mIRmJ304qZGQyp14qk2cDs0qK5ETF3GKXOBH4a\nG3467BwRayTtCvxO0s0RcWetgziRm5nBkPqRp6RdLXGvASaX5ielZYOZCZxQcew16f+VkhZRtJ/X\nTORuWjEzg2b2WlkMTJW0i6SxFMl6o94nkvYAdgCuLi3bQdK49HgCcCCwvHLfSi2rkacgZ/B829Aa\nYH5E3NKqMs3Mhq1vfVMOExG9kk4EFgI9wHkRsUzSmcCSiBhI6jOBeRFR/q3QVwLnSuqnqGifXe7t\nUk1LErmkT1FciZ0H/DEtngRcKGleRJzdinLNzIatibfoR8QCYEHFstMr5s8YZL+rgL2HWl6rauQf\nBPaKiA0+4iR9FVgGDJrIyxcQvnnOF/jQsUe3KDwzswq+RX8j/cBOwD0Vy1+a1g2qfAFh/YMro9p2\nZmZN50GzNnIycKmkO3i+P+XLgFcAJ7aoTDOz4XMi31BE/EbSbhR3OJUvdi6OBnrTm5mNtmjSxc52\naFmvlSh+kvqaVh3fzKyp3EZuZpY5N62YmWXONXIzs8y5Rm5mljnXyM3MMtfbnB+WaAcncjMzcI3c\nzCx7biM3M8uca+RmZplzjdzMLHOukZuZZc69VszMMhf5jpztRG5mBm4jNzPLnhO5mVnmfLHTzCxz\nffn+5k3HJvLT9z+t3SE03blbjmt3CC3xy81e2+4Qmu5zD1zR7hBaYl1vvr+C03JuWjEzy5wTuZlZ\n5txGbmaWt+h3P3Izs7y5acXMLHPutWJmljnXyM3MMudEbmaWOQ+aZWaWOdfIzcwyl3H3wzHtDsDM\nrCP09TU+1SFpuqTbJK2QdGqVbd4jabmkZZJ+VFp+nKQ70nRcI6G7Rm5mBkSTmlYk9QBzgEOB1cBi\nSfMjYnlpm6nAp4EDI+IRSTum5S8APgvsDwRwXdr3kVplukZuZgZF00qjU20HACsiYmVErAPmATMq\ntvkwMGcgQUfE/Wn5W4FLIuLhtO4SYHq9Ap3IzcygGGulwUnSbElLStPs0pEmAqtK86vTsrLdgN0k\nXSnpGknTh7DvRty0YmYGQ7rYGRFzgbkjKG0zYCpwEDAJ+L2kvUdyMDMz623aLfprgMml+UlpWdlq\n4NqIWA/cJel2isS+hiK5l/ddVK9AN62YmcGQmlbqWAxMlbSLpLHATGB+xTYXkxK2pAkUTS0rgYXA\nYZJ2kLQDcFhaVpNr5GZm0LR+5BHRK+lEigTcA5wXEcsknQksiYj5PJ+wlwN9wCci4iEASZ+n+DAA\nODMiHq5XphO5mRnN634IEBELgAUVy04vPQ7gY2mq3Pc84LyhlOdEbmYGWd/Z6URuZgZZJ/JRv9gp\n6QOjXaaZWV1NvEV/tLWj18rnqq0od7Jf+viK0YzJzDZx0R8NT52mJU0rkm6qtgp4cbX9yp3sPz3l\nmM57tsyse3Vggm5Uq9rIX0wxZkDlQC8CrmpRmWZmw+fxyDfyK2DriFhauULSohaVaWY2fK6Rbygi\nPlhj3TGtKNPMbEScyM3M8hZ9bloxM8uba+RmZnnrxG6FjXIiNzMD18jNzLKXbxO5E7mZGUD05pvJ\nncjNzMA1cjOz3Plip5lZ7lwjNzPLm2vkZma5c43czCxv0dvuCIbPidzMDAjXyM3MMudEbmaWN9fI\nzcwy50TeAt96eEm7Q2i6xdvt0u4QWuIXs9a1O4Smu+kH+7Y7hJa4+IEb2h1Cx4o+tTuEYevYRG5m\nNppcIzczy1z0u0ZuZpY118jNzDIX4Rq5mVnWXCM3M8tcf8a9Vsa0OwAzs04Q/Wp4qkfSdEm3SVoh\n6dQa2x0pKSTtn+anSHpa0tI0/XcjsbtGbmZG83qtSOoB5gCHAquBxZLmR8Tyiu22AU4Crq04xJ0R\nMW0oZbpGbmYGRDQ+1XEAsCIiVkbEOmAeMGOQ7T4PfAl4ZqSxV62RS/olUDXkiDh8pIWbmXWKJvYj\nnwisKs2vBl5b3kDSvsDkiPi1pE9U7L+LpBuAtcBpEfGHegXWalr5SmMxm5nlbyjdDyXNBmaXFs2N\niLkN7jsG+Cowa5DV9wEvi4iHJO0HXCxpr4hYW+uYVRN5RFzeSFBmZt2gbwi9VlLSrpa41wCTS/OT\n0rIB2wCvAhZJAngJMF/S4RGxBHg2lXGdpDuB3YCag0/VvdgpaSpwFrAnML50IrvW29fMLBdNvCFo\nMTBV0i4UCXwmcMzz5cRjwISBeUmLgFMiYomkFwEPR0SfpF2BqcDKegU20mvlu8Bnga8BbwY+AOTb\n4dLMbBDNaiOPiF5JJwILgR7gvIhYJulMYElEzK+x+xuBMyWtp/ipi+Mj4uF6ZTaSyLeIiEslKSLu\nAc6Q9AeK5G5m1hUa6I0yhGPFAmBBxbLTq2x7UOnxz4CfDbW8RhL5s6lx/o70KbMG2HGoBZmZdbJu\nH/3wJGBL4CMU/R4PBo5rZVBmZqOtrz/f22rqJvKIWJwePkHRPm5m1nWa2bQy2hrptXIZg9wYFBEH\ntyQiM7M26O/yYWxPKT0eDxwJ9NbbSdIeFHc4XRsRT5SWT4+I3ww1UDOzVurq8cgj4rqKRVdKqnmz\nkKSPACcAtwDfkXRSRPwirf43wInczDpKtzetvKA0OwbYj+JOpFo+DOwXEU9ImgL8VNKUiPgPavRB\nL9/2utW4HRk/drt64ZmZNUW3N61cR9FGLoomlbuAD9bZZ8xAc0pE3C3pIIpkvjM1Enn5ttcJ2+6W\n8eejmeWmq3utAK+MiA2GWZQ0rs4+f5U0LSKWAqSa+TuB84C9hxeqmVnr5FxzbOQj6KpBll1dZ59j\ngb+UF0REb0QcS3ELqplZR+kPNTx1mlrjkb+EotfJFpL24fkmkW0pbhCqKiJW11h35TDiNDNrqW7t\ntfJWivFyJwHn8HwiXwv8a2vDMjMbXf3tDmAEao1H/n3g+5KOTAO5mJl1rch4UNdG2sj3k7T9wIyk\nHSR9oYUxmZmNut5Qw1OnaSSRvy0iHh2YiYhHgLe3LiQzs9EXqOGp0zTS/bBH0riIeBZA0hZAve6H\nZmZZ6co28pIfApdK+i7FBc9ZwPdbGZSZ2WjrxJp2oxoZa+VLkm4EDqHoM78Q2LnVgZmZjaZur5ED\n/JUiiR9FcYu+e7GYWVfp68YauaTdgKPT9CBwEaCIePMoxWZmNmoy/qW3mjXyW4E/AO+MiBUAkj46\nKlGZmY2y/oxr5LW6H/4dcB9wmaRvSXoLNUYuNDPLWQxh6jRVE3lEXBwRM4E9gMuAk4EdJf2XpMNG\nK0Azs9HQP4Sp09S9ISginoyIH0XEuyjGXbkB+FTLIzMzG0X9UsNTp2m01wrw3F2dz/34g5lZt+hr\ndwAjMKREbmbWrbq114qZ2SYj514rHZvIH3vmyXaH0HRXrLul3SG0xCnnv67dITTdN173SLtDaInt\nrz2g3SF0rE7sjdKojk3kZmajyU0rZmaZ68RuhY1yIjczA/pcIzczy1vONfJGfiHIzKzrNfPOTknT\nJd0maYWkUwdZf7ykmyUtlXSFpD1L6z6d9rtN0lsbid2J3MwMCDU+1SKpB5gDvA3YEzi6nKiTH0XE\n3hExDfgy8NW0757ATGAvYDrwzXS8mpzIzcxoao38AGBFRKyMiHXAPGBGeYOIWFua3Yrnez/OAOZF\nxLMRcRewIh2vJreRm5kxtFv0Jc0GZpcWzY2IgaFLJgKrSutWA68d5BgnAB8DxgIHl/a9pmLfifXi\ncSI3M2No/chT0h7RmFMRMQeYI+kY4DTguOEey00rZmY0tWllDTC5ND8pLatmHnDEMPcFnMjNzICm\nJvLFwFRJu0gaS3Hxcn55A0lTS7PvAO5Ij+cDMyWNk7QLMBX4Y70C3bRiZkbzxlqJiF5JJwILgR7g\nvIhYJulMYElEzAdOlHQIsB54hNSskrb7MbAc6AVOiIi6zfdO5GZmNHeslYhYACyoWHZ66fFJNfb9\nIvDFoZTnRG5mhn9Ywswse/0ZD2TrRG5mRt5jrTiRm5nhH5YwM8uea+RmZpnrVb51cidyMzPctDIo\nSQcAERGL09CM04FbU/9KM7OO4qaVCpI+SzEW72aSLqEY+esy4FRJ+6QO72ZmHcPdDzf2bmAaMA74\nCzApItZK+gpwLVXuWioPDTmmZzvGjNmqReGZmW0o3zTeukTem8YHeErSnQODqEfE05KqfoMpDw25\n+diJOT+vZpYZN61sbJ2kLSPiKWC/gYWStiPv58vMulRfxnXyViXyN0bEswARUU7cmzOCwdPNzFol\n5xpmSxL5QBIfZPmDwIOtKNPMbCTCNXIzs7y5Rm5mljl3PzQzy1y+adyJ3MwMgN6MU7kTuZkZvthp\nZpY9X+w0M8uca+RmZplzjdzMLHN94Rq5mVnW3I/czCxzbiM3M8uc28jNzDLnphUzs8y5acXMLHPu\ntWJmljk3rbTAmDFj2h1C0/X297U7hJa46KEb2h1C0/VeO63dIbTE//3h4e0OoWPlfLGz+7Klmdkw\nxBD+1SNpuqTbJK2QdOog698o6XpJvZLeXbGuT9LSNM1vJPaOrZGbmY2mZjWtSOoB5gCHAquBxZLm\nR8Ty0mZ/BmYBpwxyiKcjYkhfCZ3IzcyAaN7FzgOAFRGxEkDSPGAG8Fwij4i707qmtOi4acXMDOgj\nGp4kzZa0pDTNLh1qIrCqNL86LWvU+HTMayQd0cgOrpGbmTG0ppWImAvMbVEoO0fEGkm7Ar+TdHNE\n3FlrB9fIzcwomlYanepYA0wuzU9KyxqNY036fyWwCNin3j5O5GZmFDXyRqc6FgNTJe0iaSwwE2io\n94mkHSSNS48nAAdSaluvxonczIzmdT+MiF7gRGAhcAvw44hYJulMSYcDSHqNpNXAUcC5kpal3V8J\nLJF0I3AZcHZFb5dBuY3czIzm3qIfEQuABRXLTi89XkzR5FK531XA3kMtz4nczAzfom9mlj0ncjOz\nzDXxhqBR50RuZoZr5GZm2fMPS5iZZa4v8h3I1onczAy3kZuZZc9t5GZmmXMbuZlZ5vozbloZtbFW\nJP1gtMoyMxuqZv7U22hrSY18kN+ZE/BmSdsDRIR/AdbMOop7rWxsEsXQi98GgiKR7w+cU2un9Csb\nswF6Ntuenp6tWxSemdmG3LSysf2B64DPAI9FxCKKHxS9PCIur7ZTRMyNiP0jYn8ncTMbTW5aqRAR\n/cDXJP0k/f/XVpVlZtYMOdfIW5pcI2I1cJSkdwBrW1mWmdlIdGJNu1GjUkuOiF8Dvx6NsszMhqMv\n+todwrC5ucPMDN+ib2aWPd+ib2aWOdfIzcwy514rZmaZc68VM7PM+RZ9M7PMuY3czCxzbiM3M8uc\na+RmZplzP3Izs8y5Rm5mljn3WjEzy5wvdpqZZc5NK2ZmmfOdnWZmmXON3Mwsczm3kSvnT6FmkTQ7\nIua2O45m68bz6sZzgu48r248p041pt0BdIjZ7Q6gRbrxvLrxnKA7z6sbz6kjOZGbmWXOidzMLHNO\n5IVubcfrxvPqxnOC7jyvbjynjuSLnWZmmXON3Mwsc07kZmaZ26QTuaTpkm6TtELSqe2OpxkknSfp\nfkl/ancszSRpsqTLJC2XtEzSSe2OaaQkjZf0R0k3pnP6XLtjaiZJPZJukPSrdsfS7TbZRC6pB5gD\nvA3YEzha0p7tjaopvgdMb3cQLdALfDwi9gReB5zQBa/Xs8DBEfFqYBowXdLr2hxTM50E3NLuIDYF\nm2wiBw4AVkTEyohYB8wDZrQ5phGLiN8DD7c7jmaLiPsi4vr0+HGKBDGxvVGNTBSeSLObp6kreh9I\nmgS8A/h2u2PZFGzKiXwisKo0v5rME8OmQtIUYB/g2vZGMnKp+WEpcD9wSURkf07J14FPAvn+WkNG\nNuVEbhmStDXwM+DkiFjb7nhGKiL6ImIaMAk4QNKr2h3TSEl6J3B/RFzX7lg2FZtyIl8DTC7NT0rL\nrENJ2pwiif8wIv6n3fE0U0Q8ClxGd1zfOBA4XNLdFE2WB0u6oL0hdbdNOZEvBqZK2kXSWGAmML/N\nMVkVkgR8B7glIr7a7niaQdKLJG2fHm8BHArc2t6oRi4iPh0RkyJiCsXf1e8i4n1tDqurbbKJPCJ6\ngROBhRQXzn4cEcvaG9XISboQuBrYXdJqSR9sd0xNciDwfora3dI0vb3dQY3QS4HLJN1EUbG4JCLc\nVc+GzLfom5llbpOtkZuZdQsncjOzzDmRm5llzonczCxzTuRmZplzIremk9SXugf+SdJPJG05gmMd\nNDB6nqTDa41SKWl7Sf88jDLOkHTKcGM0azcncmuFpyNiWkS8ClgHHF9eqcKQ33sRMT8izq6xyfbA\nkBO5We6cyK3V/gC8QtIUSbdI+iZwPTBZ0mGSrpZ0faq5bw3PjRN/q6QrgL8bOJCkWZK+kR6/WNLP\n01jeN0p6PXA28PL0beDf03afkLRY0k3l8b4lfSaNRf+/wO6j9myYtYATubWMpM0oxnu/OS3aHfhB\nROwDPAmcBhwSEfsCS4CPSRoPfAt4F/AG4CVVDv+fwOVpLO99gWXAqcCd6dvAJyQdBkylGLJ4GrCf\npDdK2o/i1vF9KD4oXtPkUzcbVZu1OwDrSlukoVmhqJF/B9gJuCcirknLX0fxgx5XFsOoMJZiaIE9\ngLsi4g6ANNjS7EHKOBg4FooRBIHHJO1Qsc1habohzW9Nkdi3AX4eEU+lMjzGjmXNidxa4ek0NOtz\nUrJ+sryIYmyRoyu222C/ERJwVkScW1HGyU0sw6zt3LRi7XINcKCkVwBI2krSbhSj/02R9PK03dFV\n9r8U+Ke0b4+k7YDHKWrbAxYC/1Bqe58oaUfg98ARkraQtA1FM45ZtpzIrS0i4gFgFnBhGv3vamCP\niHiGoinl1+li5z1VDnES8GZJNwPXAXtGxEMUTTV/kvTvEfFb4EfA1Wm7nwLbpJ+MuwhYSjG++R9a\ndqJmo8CjH5qZZc41cjOzzDmRm5llzonczCxzTuRmZplzIjczy5wTuZlZ5pzIzcwy9/8BUhZ2VZ3f\nQXoAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1664c3a8358>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1663bc26198>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#y_true = y_test.argmax(axis=1)\n",
    "#preds = multiple_own_emb.model.predict_classes(X_test)\n",
    "\n",
    "cm = ConfusionMatrix(y_true, preds)\n",
    "cm.plot(backend='seaborn', normalized=True)\n",
    "plt.title('Confusion Matrix Stars prediction')\n",
    "plt.figure(figsize=(12, 10))\n",
    "# cm.classification_report\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>F1_score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Classes</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.719376</td>\n",
       "      <td>0.810044</td>\n",
       "      <td>0.762023</td>\n",
       "      <td>30007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.586495</td>\n",
       "      <td>0.433857</td>\n",
       "      <td>0.49876</td>\n",
       "      <td>29890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.501237</td>\n",
       "      <td>0.588196</td>\n",
       "      <td>0.541246</td>\n",
       "      <td>29973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.548538</td>\n",
       "      <td>0.525664</td>\n",
       "      <td>0.536857</td>\n",
       "      <td>30120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.726707</td>\n",
       "      <td>0.727991</td>\n",
       "      <td>0.727348</td>\n",
       "      <td>30010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>__avg / total__</th>\n",
       "      <td>0.616471</td>\n",
       "      <td>0.617233</td>\n",
       "      <td>0.613297</td>\n",
       "      <td>150000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                precision    recall  F1_score support\n",
       "Classes                                              \n",
       "0                0.719376  0.810044  0.762023   30007\n",
       "1                0.586495  0.433857   0.49876   29890\n",
       "2                0.501237  0.588196  0.541246   29973\n",
       "3                0.548538  0.525664  0.536857   30120\n",
       "4                0.726707  0.727991  0.727348   30010\n",
       "__avg / total__  0.616471  0.617233  0.613297  150000"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm.classification_reportfication_report"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
